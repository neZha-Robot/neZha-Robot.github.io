<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>财经笔记--做空</title>
      <link href="/2023/05/15/%E9%A6%99%E6%B8%AF%E4%BF%9D%E5%8D%AB%E6%88%98/"/>
      <url>/2023/05/15/%E9%A6%99%E6%B8%AF%E4%BF%9D%E5%8D%AB%E6%88%98/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="一、名词解释"><a href="#一、名词解释" class="headerlink" title="一、名词解释"></a>一、名词解释</h1><p><strong>做空（Short sale）</strong>，是一个投资术语，是金融资产的一种操作模式。与做多相对，做空是先&#x3D;&#x3D;<strong>借入</strong>&#x3D;&#x3D;标的资产，然后卖出获得现金，过一段时间之后，再支出现金买入标的资产归还。</p><p><strong>多空策略</strong>（Long-Short Strategy）是指在买进一部分资产（做空）的同时，卖出另一部分资产（做多），以达到追求收益和控制风险的目的。</p><h1 id="二、做空"><a href="#二、做空" class="headerlink" title="二、做空"></a>二、做空</h1><h2 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h2><ul><li>优先收益</li><li>无限风险</li></ul><h2 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h2><ul><li>多空策略</li><li>出研究报告（浑水公司）</li></ul><h2 id="风险"><a href="#风险" class="headerlink" title="风险"></a>风险</h2><ul><li>资本反击</li><li>轧空风险</li></ul><p>借用&#x3D;&#x3D;<strong>巫师财经</strong>&#x3D;&#x3D;的话：“</p><p>​但是这场战役对我们意义重大，1998年那会儿，欧美看咱们就跟看个*，衣衫褴褛，愚昧落后，在他们眼中，98年的我们就是个落后的第三世界国家，在这些金融大鳄眼中，我们的经济金融实力如同东南亚小国一样可以任人鱼肉，他们认为他们可以如探囊取物般从香港掠夺巨量的财富，甚至不惜把香港蹂躏至三大市场崩溃，汇率制度崩盘，人民几十年辛勤劳动积累的财富化为乌有，但是我们成功阻止了这场噩梦的发生，这一场打赢在家门口的硬仗，有着特殊的意义。</p><p>​我们都看到了中国在各个领域的崛起：政治和外交话语权的逐步扩大，军事领域国防力量的推陈出新，航天领域新的技术突破，中国资本走向世界，还有我们的高铁、基建、5G等等，我们在这些看的见的地方站起来了，甚至在一些领域引领全球，然而在你们看不到的金融领域，在这些数字和博弈的背后，在各种交易、算法和规则的斡旋背后，我们也用一场场硬仗维护着中华民族的尊严和威慑，这次索罗斯代表的国际游资撞到我们这块钢板，是在向全世界传达一个重要信息——这个市场不好惹。一场硬仗让家门外的豺狼虎豹不敢轻易大举攻击人民币，给未来的人民币汇率稳定和十几年的经济腾飞打下坚实基础，我们的果敢和坚定反击让这些秃鹫一直对中国主权金融实体保有敬畏，在帷幕前的成就也是来自于帷幕后的支撑，1998年后的中国在国际上披荆斩棘，我们的经济列车过关斩将，历史车轮滚滚向前，时代洪流浩浩汤汤，广袤的华夏大地上一幅幅绚丽壮阔的史诗不断盛开，中华民族能以更加昂扬的姿态立于世界之林，纵横20余年，在世界的海洋中，中国号这艘巨轮，承载着我们共同意志和向往，凝聚着台前幕后各行各业奋斗进取的磅礴力量，虽然周围暗涌环伺，但我们依旧昂扬向前，在看的见的地方站的直是因为在看不见的地方站的稳，这也是那一代先驱传承下来的隐形宝藏。</p><p>“</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>电商在线评论分析</title>
      <link href="/2023/04/30/%E7%94%B5%E5%95%86%E5%9C%A8%E7%BA%BF%E8%AF%84%E8%AE%BA%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/"/>
      <url>/2023/04/30/%E7%94%B5%E5%95%86%E5%9C%A8%E7%BA%BF%E8%AF%84%E8%AE%BA%E6%96%87%E6%9C%AC%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>​</p><p><strong>文本挖掘：从大量文本数据中抽取出有价值的知识，并且利用这些知识重新组织信息的过程。</strong></p><h1 id="一、数据预处理"><a href="#一、数据预处理" class="headerlink" title="一、数据预处理"></a>一、数据预处理</h1><h2 id="1-1缺失值处理"><a href="#1-1缺失值处理" class="headerlink" title="1.1缺失值处理"></a>1.1缺失值处理</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df = df.dropna() <span class="comment">#删除存在缺失值的行</span></span><br></pre></td></tr></table></figure><h2 id="1-2重复值处理"><a href="#1-2重复值处理" class="headerlink" title="1.2重复值处理"></a>1.2重复值处理</h2><p>由于文本评论数据质量高低不一，无用的文本数据很多，所以文本去重就可以删掉许多的没意义的评论。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dfdrop_duplicates(inplace=<span class="literal">True</span>)<span class="comment">#删除重复记录</span></span><br></pre></td></tr></table></figure><h2 id="1-3机械压缩"><a href="#1-3机械压缩" class="headerlink" title="1.3机械压缩"></a>1.3机械压缩</h2><p>经过文本去重后的评论仍然有很多评论需要处理，比如：“好好好好好好好好好好好”，这种存在连续重复的语句，也是比较常见的无意义文本。这一类语句是需要删除的，但计算机不能自动识别出所有这种类型的语句，若不处理，可能会影响评论情感倾向的判断。因此，需要对语料进行机械压缩去词处理，也就是说要去掉一些连续重复的表达，比如把：“不错不错不错”缩成“不错”。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义机械压缩去重函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">yasuo</span>(<span class="params">st</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">int</span>(<span class="built_in">len</span>(st)/<span class="number">2</span>)+<span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(st)):</span><br><span class="line">            <span class="keyword">if</span> st[j:j+i] == st[j+i:j+<span class="number">2</span>*i]:</span><br><span class="line">                k = j + i</span><br><span class="line">                <span class="keyword">while</span> st[k:k+i] == st[k+i:k+<span class="number">2</span>*i] <span class="keyword">and</span> k&lt;<span class="built_in">len</span>(st):   </span><br><span class="line">                    k = k + i</span><br><span class="line">                st = st[:j] + st[k:]    </span><br><span class="line">    <span class="keyword">return</span> st</span><br><span class="line">yasuo(st=<span class="string">&quot;啊啊啊啊啊啊啊&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对comment列进行操作</span></span><br><span class="line">df[<span class="string">&quot;comment&quot;</span>] = df[<span class="string">&quot;comment&quot;</span>].apply(yasuo)</span><br></pre></td></tr></table></figure><h2 id="1-4文本内容清理"><a href="#1-4文本内容清理" class="headerlink" title="1.4文本内容清理"></a>1.4文本内容清理</h2><p>文中的表达符号、特殊字符，通常对文本分析的作用不大，删除。删除文本中的指定字符用正则匹配的方式。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pattern = re.<span class="built_in">compile</span>(<span class="string">u&#x27;[^\u4e00-\u9fa5a-zA-Z0-9]+&#x27;</span>)</span><br><span class="line"><span class="comment"># 定义函数，用于删除非中文、英文和数字字符</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clean_text</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">return</span> re.sub(pattern, <span class="string">&#x27;&#x27;</span>, text)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对comment列进行操作    </span></span><br><span class="line">df[<span class="string">&#x27;clean_comment&#x27;</span>] = df[<span class="string">&#x27;comment&#x27;</span>].apply(clean_text)</span><br></pre></td></tr></table></figure><h1 id="二、中文分词"><a href="#二、中文分词" class="headerlink" title="二、中文分词"></a>二、中文分词</h1><h2 id="2-1概念"><a href="#2-1概念" class="headerlink" title="2.1概念"></a>2.1概念</h2><p><strong>中文分词（Chinese Word Segmentation）</strong>：将一个汉字序列切分成一个一个单独的词。</p><p>eg：我的家乡是广东省湛江市–&gt;我&#x2F;的&#x2F;家乡&#x2F;是&#x2F;广东省&#x2F;湛江市</p><p><strong>停用词（Stop Words）：</strong><br>数据处理时，需要过滤掉某些字或词</p><h2 id="2-2代码实现"><a href="#2-2代码实现" class="headerlink" title="2.2代码实现"></a>2.2代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> jieba.posseg <span class="keyword">as</span> pseg</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载停用词表</span></span><br><span class="line">stopwords = <span class="built_in">set</span>(pd.read_csv(<span class="string">&#x27;/home/aistudio/dict/stopwords.txt&#x27;</span>, header=<span class="literal">None</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>, squeeze=<span class="literal">True</span>))</span><br><span class="line"><span class="comment"># 加载自定义词典</span></span><br><span class="line">jieba.load_userdict(<span class="string">&#x27;/home/aistudio/dict/dict.txt&#x27;</span>)</span><br><span class="line"><span class="comment"># 定义需要替换的词和替换成的词</span></span><br><span class="line">replace_dict = &#123;</span><br><span class="line">    <span class="string">&#x27;老师&#x27;</span>: <span class="string">&#x27;教师&#x27;</span>,</span><br><span class="line">    <span class="string">&#x27;医生&#x27;</span>: <span class="string">&#x27;医务工作者&#x27;</span>,</span><br><span class="line">    <span class="comment"># 可以继续添加需要替换的词和替换成的词</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 定义选择词性的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">select_words</span>(<span class="params">words, pos</span>):</span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> word, tag <span class="keyword">in</span> words:</span><br><span class="line">        <span class="keyword">if</span> tag <span class="keyword">in</span> pos <span class="keyword">and</span> word <span class="keyword">not</span> <span class="keyword">in</span> stopwords:</span><br><span class="line">            <span class="comment"># 替换词</span></span><br><span class="line">            <span class="keyword">for</span> k, v <span class="keyword">in</span> replace_dict.items():</span><br><span class="line">                word = word.replace(k, v)</span><br><span class="line">            result.append(word)</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27; &#x27;</span>.join(result)</span><br><span class="line"><span class="comment"># 定义分词函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cut_comment</span>(<span class="params">comment, pos</span>):</span><br><span class="line">    <span class="comment"># 分词</span></span><br><span class="line">    words = pseg.cut(comment)</span><br><span class="line">    <span class="comment"># 选择词性</span></span><br><span class="line">    result = select_words(words, pos)</span><br><span class="line">    <span class="comment"># 返回结果</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"><span class="comment"># 指定要读取的文件夹路径</span></span><br><span class="line">folder_path = <span class="string">&quot;data_clean&quot;</span></span><br><span class="line">folder_path1 = <span class="string">&quot;data_cut&quot;</span></span><br><span class="line"><span class="comment"># 获取文件夹中的所有xlsx文件</span></span><br><span class="line">file_list = [f <span class="keyword">for</span> f <span class="keyword">in</span> os.listdir(folder_path) <span class="keyword">if</span> f.endswith(<span class="string">&#x27;.xlsx&#x27;</span>)]</span><br><span class="line"><span class="comment"># 循环读取每个xlsx文件，并对其中的comment列进行操作</span></span><br><span class="line"><span class="keyword">for</span> file_name <span class="keyword">in</span> file_list:</span><br><span class="line">    file_path = os.path.join(folder_path, file_name)</span><br><span class="line">    <span class="comment"># 读取Excel文件</span></span><br><span class="line">    data = pd.read_excel(file_path)</span><br><span class="line">    <span class="comment"># 对clean_comment列应用分词函数</span></span><br><span class="line">    df[<span class="string">&#x27;cut_comment&#x27;</span>] = df[<span class="string">&#x27;clean_comment&#x27;</span>].apply(<span class="keyword">lambda</span> x: cut_comment(x, [<span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;v&#x27;</span>, <span class="string">&#x27;vn&#x27;</span>, <span class="string">&#x27;an&#x27;</span>]))<span class="comment">#保留名词 动词 形容词</span></span><br><span class="line">    <span class="comment"># 将结果保存到一个新的Excel文件中</span></span><br><span class="line">    new_file_name = <span class="string">&#x27;new_&#x27;</span> + file_name</span><br><span class="line">    new_file_path = os.path.join(folder_path1, new_file_name)</span><br><span class="line">    data.to_excel(new_file_path, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h1 id="3-TF-IDF"><a href="#3-TF-IDF" class="headerlink" title="3.TF-IDF"></a>3.TF-IDF</h1><h2 id="3-1TF-IDF算法介绍"><a href="#3-1TF-IDF算法介绍" class="headerlink" title="3.1TF-IDF算法介绍"></a>3.1<strong>TF-IDF算法介绍</strong></h2><p>​<strong>TF-IDF（term frequency–inverse document frequency，词频-逆向文件频率）</strong>是一种用于信息检索（information retrieval）与文本挖掘（text mining）的常用<strong>加权技术</strong>。</p><p>​TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。<strong>字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。</strong></p><p>​TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。<strong>字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。</strong></p><h2 id="3-2代码实现"><a href="#3-2代码实现" class="headerlink" title="3.2代码实现"></a>3.2代码实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据</span></span><br><span class="line">folder_path = <span class="string">&quot;data_cut&quot;</span></span><br><span class="line"><span class="comment"># 获取文件夹中的所有xlsx文件</span></span><br><span class="line">file_list = [f <span class="keyword">for</span> f <span class="keyword">in</span> os.listdir(folder_path) <span class="keyword">if</span> f.endswith(<span class="string">&#x27;.xlsx&#x27;</span>)]</span><br><span class="line"><span class="comment"># 循环读取每个xlsx文件，并对其中的comment列进行操作</span></span><br><span class="line"><span class="keyword">for</span> file_name <span class="keyword">in</span> file_list:</span><br><span class="line">    file_path = os.path.join(folder_path, file_name)</span><br><span class="line">    <span class="comment"># 读取Excel文件</span></span><br><span class="line">    data = pd.read_excel(file_path)</span><br><span class="line">    data = data.dropna() <span class="comment">#删除存在缺失值的行</span></span><br><span class="line">    merged_df = data.append(data, ignore_index=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment"># 输出分词结果</span></span><br><span class="line">    text = <span class="string">&#x27;&#x27;</span>.join(data[<span class="string">&#x27;cut_comment&#x27;</span>].tolist())</span><br><span class="line">    <span class="comment"># 对拼接后的文本进行关键词提取</span></span><br><span class="line">    keywords = jieba.analyse.extract_tags(text, topK=<span class="number">20</span>, withWeight=<span class="literal">True</span>, allowPOS=(<span class="string">&#x27;n&#x27;</span>, <span class="string">&#x27;a&#x27;</span>, <span class="string">&#x27;v&#x27;</span>, <span class="string">&#x27;vn&#x27;</span>, <span class="string">&#x27;an&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(file_name)</span><br><span class="line">    <span class="built_in">print</span>(keywords)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 将合并后的 DataFrame 保存为新的 Excel 文件</span></span><br><span class="line">merged_df.to_excel(<span class="string">&quot;merged.xlsx&quot;</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><h1 id="4-情感分析"><a href="#4-情感分析" class="headerlink" title="4.情感分析"></a>4.情感分析</h1><p>​对于评论“物流挺不错的。价格也还可以。”即可拆分为“物流挺不错的”和“价格也还可以”两条评论。利用扩充后的主题词典，通过属性词匹配的方式，找出包含主题词的评论分句，统计各评价维度对应的评论分句数量。假定一条分句中，仅包含评论者对评论实体某一主题的评价，将分句情感得分的结果转换为对评价主体属性的得分。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> snownlp <span class="keyword">import</span> SnowNLP</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 主题词典</span></span><br><span class="line">topic_dict = &#123;<span class="string">&quot;价格&quot;</span>: [<span class="string">&quot;便宜&quot;</span>, <span class="string">&quot;贵&quot;</span>, <span class="string">&quot;优惠&quot;</span>, <span class="string">&quot;划算&quot;</span>],</span><br><span class="line">              <span class="string">&quot;口感&quot;</span>: [<span class="string">&quot;好吃&quot;</span>, <span class="string">&quot;难吃&quot;</span>, <span class="string">&quot;美味&quot;</span>],</span><br><span class="line">              <span class="string">&quot;服务&quot;</span>: [<span class="string">&quot;态度&quot;</span>, <span class="string">&quot;热情&quot;</span>, <span class="string">&quot;周到&quot;</span>],</span><br><span class="line">              <span class="string">&quot;物流&quot;</span>: [<span class="string">&quot;物流&quot;</span>, <span class="string">&quot;快&quot;</span>]&#125;<span class="comment">#示例</span></span><br><span class="line"><span class="comment"># 提取评论中的句子</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_sentences</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="comment"># 将文本分为句子</span></span><br><span class="line">    sentences = re.split(<span class="string">r&#x27;[。！？]&#x27;</span>, text)</span><br><span class="line">    <span class="comment"># 去除空句子</span></span><br><span class="line">    sentences = [sent.strip() <span class="keyword">for</span> sent <span class="keyword">in</span> sentences <span class="keyword">if</span> <span class="built_in">len</span>(sent.strip()) &gt; <span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> sentences</span><br><span class="line"><span class="comment"># 匹配主题词</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">match_topic</span>(<span class="params">sentence, topic_dict</span>):</span><br><span class="line">    <span class="comment"># 初始化主题词</span></span><br><span class="line">    topic = <span class="literal">None</span></span><br><span class="line">    <span class="comment"># 遍历主题词典</span></span><br><span class="line">    <span class="keyword">for</span> t, attributes <span class="keyword">in</span> topic_dict.items():</span><br><span class="line">        <span class="comment"># 判断主题词是否在句子中</span></span><br><span class="line">        <span class="keyword">if</span> t <span class="keyword">in</span> sentence:</span><br><span class="line">            topic = t</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> topic</span><br><span class="line"><span class="comment"># 读取评论数据</span></span><br><span class="line">df = pd.read_excel(<span class="string">&quot;寺库.xlsx&quot;</span>)</span><br><span class="line"><span class="comment"># 对主题词进行情感分析</span></span><br><span class="line"><span class="keyword">for</span> topic <span class="keyword">in</span> topic_dict:</span><br><span class="line">    topic_sentiments = []</span><br><span class="line">    <span class="keyword">for</span> comment <span class="keyword">in</span> df[<span class="string">&quot;comment&quot;</span>]:</span><br><span class="line">        <span class="comment"># 分句</span></span><br><span class="line">        sentences = extract_sentences(comment)</span><br><span class="line">        <span class="comment"># 遍历句子</span></span><br><span class="line">        <span class="keyword">for</span> sentence <span class="keyword">in</span> sentences:</span><br><span class="line">            <span class="comment"># 匹配主题词</span></span><br><span class="line">            <span class="keyword">if</span> match_topic(sentence, topic_dict) == topic:</span><br><span class="line">                <span class="comment"># 进行情感分析</span></span><br><span class="line">                s = SnowNLP(sentence)</span><br><span class="line">                sentiment = s.sentiments</span><br><span class="line">                topic_sentiments.append(sentiment)</span><br><span class="line">    <span class="comment"># 输出主题词情感分析结果</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(topic_sentiments) &gt; <span class="number">0</span>:</span><br><span class="line">        avg_sentiment = <span class="built_in">sum</span>(topic_sentiments) / <span class="built_in">len</span>(topic_sentiments)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;topic&#125;</span>的情感倾向为：<span class="subst">&#123;avg_sentiment:<span class="number">.2</span>f&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p><strong>注：大三的时候第一次做这个项目，大四又做了一次，但因为没有这方面的基础，所以做的很粗糙，写的更加粗擦。之前参考其它博主的文章时，总是抱怨不够详细，直到自己写才知道这难度，不过好在给博客项目开了个头。</strong></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2023/04/29/hello-world/"/>
      <url>/2023/04/29/hello-world/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p>​</p><p>亲爱的世界，</p><p>​本来是想做<a href="%5B1%E4%BA%BA1%E5%A4%A9%EF%BC%8C%E6%88%91%E5%81%9A%E4%BA%86%E4%B8%AA%E7%BC%96%E7%A8%8B%E5%A4%A7%E7%99%BE%E7%A7%91%E7%BD%91%E7%AB%99%EF%BC%81%E8%80%8C%E4%B8%94%E3%80%82%E3%80%82%E3%80%82_%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9_bilibili%5D(https://www.bilibili.com/video/BV19M4y127fG/?spm_id_from=333.999.0.0)">鱼皮的百科全书</a>，但是弄着弄着就变成这个样子了，不过这也算是一次成功的尝试。</p><p>​跟着网上的教程慢慢摸索，花了几天时间终于弄出来一个博客的大概。看到edge中网页成功加载出来的那一刻，心里有种新世界大门向我打开的感觉…</p><p>​“ChatGPT的震撼相信大家都已经体验过了，我们这一代人有幸见证了40年以来最大的AI革命，这个时代有像是OpenAi和波士顿动力这样的团队珠玉在前，希望在未来AI和机器人融合的进程中……。立于皓月之边，不弱星光之势。“借<strong>稚晖君</strong>的话在此共勉，唯有热爱可抵岁月漫长。</p><p>​这不是结束，甚至不是结束的开始，而是开始的结束。</p><p>​<strong>祝我玩的开心</strong></p><p>​                                                                                                                                                                                   敬礼，</p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
